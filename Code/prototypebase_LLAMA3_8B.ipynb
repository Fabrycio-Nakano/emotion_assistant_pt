{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec6a15cd09c546cca10f36ccaf08ee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b37d505b2046431baeeabec07a2f502a",
              "IPY_MODEL_d976176df3634d3d874a44f6372f7d64",
              "IPY_MODEL_51197fffde224631aa617858cb06b9b5"
            ],
            "layout": "IPY_MODEL_ec35e19aed0e45a6bd4db730394462b7"
          }
        },
        "b37d505b2046431baeeabec07a2f502a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190251599f474d99b70ce8b86d9d4286",
            "placeholder": "​",
            "style": "IPY_MODEL_116e3cdd360e41589ae784f79072e7d6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d976176df3634d3d874a44f6372f7d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6c5b7050db74776a2e10186bf83eb68",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28fea0e885064f9ca2a216ef40215d52",
            "value": 4
          }
        },
        "51197fffde224631aa617858cb06b9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883202626eac4c7a805dfbb0ea02a78c",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e075360a3a4ed2a7797111a248cab7",
            "value": " 4/4 [01:24&lt;00:00, 18.16s/it]"
          }
        },
        "ec35e19aed0e45a6bd4db730394462b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190251599f474d99b70ce8b86d9d4286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116e3cdd360e41589ae784f79072e7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c5b7050db74776a2e10186bf83eb68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28fea0e885064f9ca2a216ef40215d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "883202626eac4c7a805dfbb0ea02a78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e075360a3a4ed2a7797111a248cab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install librosa==0.9.0 pydub noisereduce scikit-learn tensorflow torchaudio seaborn matplotlib sqlalchemy smtplib\n",
        "!pip install -U funasr modelscope\n",
        "!pip install addict\n",
        "!pip install datasets==2.18.0\n",
        "!pip install simplejson\n",
        "!sudo apt update && sudo apt install ffmpeg\n"
      ],
      "metadata": {
        "id": "Ye1RxIqcKLnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import librosa\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import pipeline\n",
        "import logging\n",
        "from modelscope.pipelines import pipeline as modelscope_pipeline\n",
        "from modelscope.utils.constant import Tasks\n",
        "from sqlalchemy import create_engine, Column, String, Integer, Text, ForeignKey\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker, relationship\n",
        "from sqlalchemy.exc import IntegrityError\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "import json\n",
        "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig)"
      ],
      "metadata": {
        "id": "5zGt-r_CKTxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_data = json.load(open(\"/content/config.json\"))\n",
        "HF_TOKEN = config_data[\"HF_TOKEN\"]\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=HF_TOKEN)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    use_auth_token=HF_TOKEN\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "ec6a15cd09c546cca10f36ccaf08ee57",
            "b37d505b2046431baeeabec07a2f502a",
            "d976176df3634d3d874a44f6372f7d64",
            "51197fffde224631aa617858cb06b9b5",
            "ec35e19aed0e45a6bd4db730394462b7",
            "190251599f474d99b70ce8b86d9d4286",
            "116e3cdd360e41589ae784f79072e7d6",
            "f6c5b7050db74776a2e10186bf83eb68",
            "28fea0e885064f9ca2a216ef40215d52",
            "883202626eac4c7a805dfbb0ea02a78c",
            "e0e075360a3a4ed2a7797111a248cab7"
          ]
        },
        "id": "8vXd3KJEKWPh",
        "outputId": "e082ad9f-28dc-45ba-a664-7169df9297e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec6a15cd09c546cca10f36ccaf08ee57"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de geração de respostas usando o template de chat\n",
        "def get_response(prompt):\n",
        "    input_data = tokenizer(\n",
        "        prompt,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    input_ids = input_data['input_ids']\n",
        "    attention_mask = input_data['attention_mask']\n",
        "\n",
        "    eos_token_id = tokenizer.eos_token_id if tokenizer.eos_token_id is not None else 2\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=100,\n",
        "        eos_token_id=eos_token_id,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    response = outputs[:, input_ids.shape[-1]:]\n",
        "    return tokenizer.decode(response[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "fA2GmstCKY0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Base = declarative_base()\n",
        "\n",
        "class Psicologo(Base):\n",
        "    __tablename__ = 'psicologos'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    nome = Column(String, unique=True)\n",
        "    email = Column(String, unique=True)\n",
        "\n",
        "class Paciente(Base):\n",
        "    __tablename__ = 'pacientes'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    nome = Column(String)\n",
        "    psicologo_id = Column(Integer, ForeignKey('psicologos.id'))\n",
        "    psicologo = relationship(\"Psicologo\", back_populates=\"pacientes\")\n",
        "\n",
        "Psicologo.pacientes = relationship(\"Paciente\", order_by=Paciente.id, back_populates=\"psicologo\")\n",
        "\n",
        "class Conversa(Base):\n",
        "    __tablename__ = 'conversas'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    paciente_id = Column(Integer, ForeignKey('pacientes.id'))\n",
        "    texto = Column(Text)\n",
        "    paciente = relationship(\"Paciente\", back_populates=\"conversas\")\n",
        "\n",
        "Paciente.conversas = relationship(\"Conversa\", order_by=Conversa.id, back_populates=\"paciente\")\n",
        "\n",
        "engine = create_engine('sqlite:///database.db')\n",
        "Base.metadata.create_all(engine)\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "\n",
        "def adicionar_psicologo(nome, email):\n",
        "    psicologo = Psicologo(nome=nome, email=email)\n",
        "    session.add(psicologo)\n",
        "    try:\n",
        "        session.commit()\n",
        "        print(f\"Psicólogo {nome} adicionado com sucesso!\")\n",
        "    except IntegrityError:\n",
        "        session.rollback()\n",
        "        psicologo = session.query(Psicologo).filter_by(nome=nome).first()\n",
        "        print(f\"Psicólogo {nome} já existe.\")\n",
        "    return psicologo\n",
        "\n",
        "def adicionar_paciente(nome, psicologo_nome, psicologo_email):\n",
        "    psicologo = session.query(Psicologo).filter_by(nome=psicologo_nome).first()\n",
        "    if not psicologo:\n",
        "        psicologo = adicionar_psicologo(psicologo_nome, psicologo_email)\n",
        "\n",
        "    paciente = Paciente(nome=nome, psicologo=psicologo)\n",
        "    session.add(paciente)\n",
        "    try:\n",
        "        session.commit()\n",
        "        print(f\"Paciente {nome} adicionado com sucesso!\")\n",
        "    except IntegrityError:\n",
        "        session.rollback()\n",
        "        print(f\"Erro ao adicionar o paciente {nome}.\")\n",
        "\n",
        "def listar_pacientes(): # Function para listar todos os pacientes\n",
        "    pacientes = session.query(Paciente).all()\n",
        "    for paciente in pacientes:\n",
        "        print(f\"ID: {paciente.id}, Nome: {paciente.nome}, Psicólogo: {paciente.psicologo.nome}\")\n",
        "\n",
        "def buscar_paciente_por_nome(nome): # Function para buscar paciente por nome\n",
        "    paciente = session.query(Paciente).filter_by(nome=nome).first()\n",
        "    if paciente:\n",
        "        return paciente.id\n",
        "    else:\n",
        "        print(f\"Paciente {nome} não encontrado.\")\n",
        "        return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptj0IoAGKb2O",
        "outputId": "4c1e58e5-1a0f-4dd3-ddc8-124cfca3d7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5424cbd80fb3>:2: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_pipeline = modelscope_pipeline(\n",
        "    task=Tasks.emotion_recognition,\n",
        "    model=\"iic/emotion2vec_plus_large\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML39lMTvKk2Z",
        "outputId": "f67dfdf6-391e-41a0-9661-b2932c6c7e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-07-11 02:35:21,661 - modelscope - WARNING - Model revision not specified, use revision: v2.0.5\n",
            "2024-07-11 02:35:22,284 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/iic/emotion2vec_plus_large\n",
            "2024-07-11 02:35:22,286 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/iic/emotion2vec_plus_large.\n",
            "2024-07-11 02:35:22,288 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/iic/emotion2vec_plus_large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the latest version of funasr-1.1.0\n",
            "Detect model requirements, begin to install it: /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/requirements.txt\n",
            "install model requirements successfully\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-07-11 02:35:46,212 - modelscope - WARNING - No preprocessor field found in cfg.\n",
            "2024-07-11 02:35:46,213 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
            "2024-07-11 02:35:46,216 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/iic/emotion2vec_plus_large'}. trying to build by task and model information.\n",
            "2024-07-11 02:35:46,217 - modelscope - WARNING - No preprocessor key ('funasr', 'emotion-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enviar_email(psicologo_email, assunto, conteudo):\n",
        "    from_email = \"seu_email@gmail.com\"  #verificar no google senhas api\n",
        "    from_password = \"sua_senha\"\n",
        "\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = from_email\n",
        "    msg['To'] = psicologo_email\n",
        "    msg['Subject'] = assunto\n",
        "\n",
        "    msg.attach(MIMEText(conteudo, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com:587')\n",
        "        server.starttls()\n",
        "        server.login(from_email, from_password)\n",
        "        server.send_message(msg)\n",
        "        server.quit()\n",
        "        print(\"Email enviado com sucesso!\")\n",
        "    except smtplib.SMTPAuthenticationError:\n",
        "        print(\"Falha na autenticação SMTP. O email não foi enviado, mas o processo continuará.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao enviar o email: {e}. O processo continuará.\")\n"
      ],
      "metadata": {
        "id": "KoiWNFJKKpGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcessadorAudio:\n",
        "    def __init__(self, taxa_amostragem_alvo=16000, n_fft=1024, hop_length=512, n_mels=64, max_pad_len=400):\n",
        "        self.taxa_amostragem_alvo = taxa_amostragem_alvo\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "        self.max_pad_len = max_pad_len\n",
        "\n",
        "    def carregar_audio(self, caminho):\n",
        "        waveform, sample_rate = torchaudio.load(caminho)\n",
        "        if sample_rate != self.taxa_amostragem_alvo:\n",
        "            resample_transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=self.taxa_amostragem_alvo)\n",
        "            waveform = resample_transform(waveform)\n",
        "        return waveform\n",
        "\n",
        "    def extrair_caracteristicas(self, waveform):\n",
        "        mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=self.taxa_amostragem_alvo,\n",
        "            n_fft=self.n_fft,\n",
        "            hop_length=self.hop_length,\n",
        "            n_mels=self.n_mels\n",
        "        )\n",
        "        mel_spectrogram = mel_spectrogram_transform(waveform)\n",
        "        mel_spectrogram = mel_spectrogram.mean(dim=0)\n",
        "        pad = self.max_pad_len - mel_spectrogram.shape[-1]\n",
        "        if pad > 0:\n",
        "            mel_spectrogram = torch.nn.functional.pad(mel_spectrogram, (0, pad))\n",
        "        else:\n",
        "            mel_spectrogram = mel_spectrogram[:, :self.max_pad_len]\n",
        "        return mel_spectrogram.numpy().flatten()"
      ],
      "metadata": {
        "id": "BCuhXfYuKr2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DetectorEmocao:\n",
        "    def __init__(self, modelo):\n",
        "        self.modelo = modelo\n",
        "        self.labels_mapping = {\n",
        "            '生气/angry': 'angry',\n",
        "            '开心/happy': 'happy',\n",
        "            '中立/neutral': 'neutral',\n",
        "            '难过/sad': 'sad',\n",
        "            '<unk>': 'unknown',\n",
        "        }\n",
        "\n",
        "    def prever(self, caminho_audio):\n",
        "        rec_result = self.modelo(caminho_audio, granularity=\"utterance\", extract_embedding=False)\n",
        "        for result in rec_result:\n",
        "            predicted_emotion = self.labels_mapping[result['labels'][np.argmax(result['scores'])]]\n",
        "            return predicted_emotion"
      ],
      "metadata": {
        "id": "XOvZuE4DKtAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcessadorNLP:\n",
        "    def __init__(self):\n",
        "        self.analisador_sentimento = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "    def analisar_sentimento(self, texto):\n",
        "        resultado = self.analisador_sentimento(texto)\n",
        "        sentimento = resultado[0]['label']\n",
        "        mapeamento_sentimentos = {\n",
        "            \"1 star\": \"sad\",\n",
        "            \"2 stars\": \"neutral\",\n",
        "            \"3 stars\": \"neutral\",\n",
        "            \"4 stars\": \"happy\",\n",
        "            \"5 stars\": \"happy\"\n",
        "        }\n",
        "        return mapeamento_sentimentos.get(sentimento, \"neutral\")"
      ],
      "metadata": {
        "id": "Bmfo7gW1KvTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeradorResposta:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def gerar_resposta(self, prompt):\n",
        "        return get_response(prompt)\n"
      ],
      "metadata": {
        "id": "zdXhAwdkKyRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AssistenteAudioEmocional:\n",
        "    def __init__(self, processador_audio, detector_emocao, processador_nlp, gerador_resposta, session):\n",
        "        self.processador_audio = processador_audio\n",
        "        self.detector_emocao = detector_emocao\n",
        "        self.processador_nlp = processador_nlp\n",
        "        self.gerador_resposta = gerador_resposta\n",
        "        self.session = session\n",
        "\n",
        "    def processar_audio(self, caminho_audio):\n",
        "        logging.info(\"Processando áudio...\")\n",
        "        return self.detector_emocao.prever(caminho_audio)\n",
        "\n",
        "    def transcrever_audio(self, caminho_audio):\n",
        "        logging.info(\"Transcrevendo áudio...\")\n",
        "        os.system(f'whisper {caminho_audio} --model medium --task transcribe --language pt --output_format txt')\n",
        "        with open(caminho_audio.replace('.m4a', '.txt'), 'r') as file:\n",
        "            transcricao = file.read()\n",
        "        return transcricao\n",
        "\n",
        "    def processar_texto(self, texto):\n",
        "        logging.info(\"Processando texto...\")\n",
        "        return self.processador_nlp.analisar_sentimento(texto)\n",
        "\n",
        "    def gerar_resposta(self, emocao_audio, emocao_texto, transcricao):\n",
        "        logging.info(\"Gerando resposta...\")\n",
        "        prompt = (f\"Você é um assistente psicólogico virtual especializado em emergências psicológicas. Abaixo o conteudo da mensagem do paciente e os sentimentos detectados. \"\n",
        "                  f\"Transcrição do áudio: {transcricao} \\n\"\n",
        "                  f\"Emoção detectada no áudio: {emocao_audio} \\n\"\n",
        "                  f\"Emoção detectada no texto transcrito: {emocao_texto} \\n\"\n",
        "                  f\"Baseado na ciencia psicologica, gere uma resposta para este paciente!Seja empatico e tome cuidado com as palavras. Forneça respostas curtas e objetivas.\")\n",
        "        #print(f\"Prompt enviado ao modelo: {prompt}\")\n",
        "        return self.gerador_resposta.gerar_resposta(prompt)\n",
        "\n",
        "    def salvar_conversa(self, paciente_id, texto):\n",
        "        conversa = Conversa(paciente_id=paciente_id, texto=texto)\n",
        "        self.session.add(conversa)\n",
        "        self.session.commit()\n",
        "\n",
        "    def enviar_relatorio(self, paciente_id):\n",
        "        paciente = self.session.query(Paciente).filter_by(id=paciente_id).first()\n",
        "        psicologo = paciente.psicologo\n",
        "        conversas = self.session.query(Conversa).filter_by(paciente_id=paciente_id).all()\n",
        "        historico = \"\\n\".join([c.texto for c in conversas])\n",
        "\n",
        "        emocao_audio = self.processar_audio(caminho_audio)\n",
        "        transcricao = self.transcrever_audio(caminho_audio)\n",
        "        emocao_texto = self.processar_texto(transcricao)\n",
        "\n",
        "        assunto = f\"Relatório da Análise de Sentimentos do Paciente {paciente.nome}\"\n",
        "        conteudo = f\"Histórico da conversa:\\n{historico}\\n\\nEmoção detectada no áudio: {emocao_audio}\\nEmoção detectada no texto: {emocao_texto}\"\n",
        "        enviar_email(psicologo.email, assunto, conteudo)\n",
        "\n",
        "    def lidar_interacao(self, caminho_audio, paciente_id):\n",
        "        emocao_audio = self.processar_audio(caminho_audio)\n",
        "        transcricao = self.transcrever_audio(caminho_audio)\n",
        "        emocao_texto = self.processar_texto(transcricao)\n",
        "        resposta = self.gerar_resposta(emocao_audio, emocao_texto, transcricao)\n",
        "        historico = \"\\n\".join([c.texto for c in self.session.query(Conversa).filter_by(paciente_id=paciente_id).all()])\n",
        "        self.salvar_conversa(paciente_id, f\"Paciente: {transcricao}\\nAssistente: {resposta}\")\n",
        "        self.enviar_relatorio(paciente_id)\n",
        "        return resposta\n"
      ],
      "metadata": {
        "id": "MkiZ12aSK0BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicialização dos componentes\n",
        "processador_audio = ProcessadorAudio()\n",
        "detector_emocao = DetectorEmocao(inference_pipeline)\n",
        "processador_nlp = ProcessadorNLP()\n",
        "gerador_resposta = GeradorResposta()"
      ],
      "metadata": {
        "id": "oDgk2N60K4OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criação do Assistente\n",
        "assistente = AssistenteAudioEmocional(processador_audio, detector_emocao, processador_nlp, gerador_resposta, session)"
      ],
      "metadata": {
        "id": "xsn-QLbUK67R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adicionar psicólogos e pacientes para o exemplo\n",
        "adicionar_psicologo(\"Dr. Maria\", \"dr.maria@example.com\")\n",
        "adicionar_paciente(\"João da Silva\", \"Dr. Maria\", \"dr.maria@example.com\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JoUW4U7K7Mz",
        "outputId": "088c1ce5-6682-4bbc-829d-49c255a03235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Psicólogo Dr. Maria já existe.\n",
            "Paciente João da Silva adicionado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# listar pacientes\n",
        "listar_pacientes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpDKc4SuK9qI",
        "outputId": "ca917518-3014-4fe5-c057-9aaeb55d1520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 1, Nome: João da Silva, Psicólogo: Dr. Maria\n",
            "ID: 2, Nome: João da Silva, Psicólogo: Dr. Maria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paciente_id = buscar_paciente_por_nome(\"João da Silva\")"
      ],
      "metadata": {
        "id": "QZl55HLtK_x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if paciente_id:\n",
        "    caminho_audio = \"/content/audio_triste.m4a\"\n",
        "    resposta = assistente.lidar_interacao(caminho_audio, paciente_id)\n",
        "    print(\"Resposta do Assistente:\", resposta)"
      ],
      "metadata": {
        "id": "pqI3On8FLDR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2188e2e4-fbce-45b6-a9bc-0f2d83b88b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "rtf_avg: 0.017: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
            "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Falha na autenticação SMTP. O email não foi enviado, mas o processo continuará.\n",
            "Resposta do Assistente:  \n",
            "\n",
            "Resposta:\n",
            "Olá! Eu estou aqui para escutar e ajudar. Pude perceber que você está sentindo um vazio no coração e no estúdio. Isso pode ser um sinal de que você está experimentando uma perda ou um sentimento de desamparo. É normal sentir isso, especialmente em momentos difíceis. Quer falar um pouco mais sobre o que está acontecendo e como você se sente? Eu est\n"
          ]
        }
      ]
    }
  ]
}