{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Fabrycio Leite Nakano Almada.\n",
        "Instituto de Informática, Universidade Federal de Goiás\n",
        "fabrycio@discente.ufg.br\n",
        "* Kauan Divino Pouso Mariano.\n",
        "Instituto de Informática, Universidade Federal de Goiás\n",
        "kauan@discente.ufg.br\n",
        "* Maykon Adriell Dutra.\n",
        "Instituto de Informática, Universidade Federal de Goiás\n",
        "maykonadriell@discente.ufg.br\n",
        "* Victor Emanuel da Silva Monteiro.\n",
        "Instituto de Informática, Universidade Federal de Goiás\n",
        "victor_emanuel@discente.ufg.br\n"
      ],
      "metadata": {
        "id": "nqnD90XvDzly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código implementa um sistema de suporte emocional contínuo que integra processamento de áudio, análise de sentimentos e geração de respostas empáticas, tudo isso auxiliado por um banco de dados robusto e uma interface de usuário amigável. O sistema é projetado para ser utilizado junto com o acompanhamento de um psicólogo, oferecendo uma ferramenta que permite aos pacientes registrar e gerenciar suas emoções em tempo real, mesmo fora das sessões de terapia."
      ],
      "metadata": {
        "id": "BGuwVAKEEOqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importações"
      ],
      "metadata": {
        "id": "rx-wYnwwqhyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências\n",
        "!pip install accelerate bitsandbytes transformers git+https://github.com/openai/whisper.git\n",
        "!pip install librosa==0.9.0 pydub noisereduce scikit-learn tensorflow torchaudio seaborn matplotlib sqlalchemy smtplib\n",
        "!pip install -U funasr modelscope addict datasets==2.18.0 simplejson gradio\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iwGmsDXLy6aS",
        "outputId": "fa7f4f69-d943-4103-d22a-34d9151f7efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-uewwf_6g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-uewwf_6g\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802821 sha256=2d664f0c27548ea93c6b29dbcb296753d142dd24b87c00b919dd52940f74a1ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xuj8zcai/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper, bitsandbytes, accelerate\n",
            "Successfully installed accelerate-0.32.1 bitsandbytes-0.43.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Collecting librosa==0.9.0\n",
            "  Downloading librosa-0.9.0-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.31)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement smtplib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for smtplib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting funasr\n",
            "  Downloading funasr-1.1.0-py3-none-any.whl (645 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.2/645.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting modelscope\n",
            "  Downloading modelscope-1.16.0-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting datasets==2.18.0\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-4.37.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.18.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (4.66.4)\n",
            "Collecting xxhash (from datasets==2.18.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.18.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from funasr) (1.11.4)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from funasr) (0.10.2.post1)\n",
            "Collecting jamo (from funasr)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from funasr) (0.12.1)\n",
            "Collecting kaldiio>=2.17.0 (from funasr)\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Collecting torch-complex (from funasr)\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from funasr) (0.1.99)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from funasr) (0.42.1)\n",
            "Collecting rotary-embedding-torch (from funasr)\n",
            "  Downloading rotary_embedding_torch-0.6.4-py3-none-any.whl (5.4 kB)\n",
            "Collecting pytorch-wpe (from funasr)\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from funasr) (0.6.2)\n",
            "Collecting oss2 (from funasr)\n",
            "  Downloading oss2-2.18.6.tar.gz (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.8/283.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn (from funasr)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaconv (from funasr)\n",
            "  Downloading jaconv-0.3.4.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.3.2 (from funasr)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX (from funasr)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from modelscope) (2.0.7)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.2 (from gradio)\n",
            "  Downloading gradio_client-1.0.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==1.0.2->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->funasr)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->funasr)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.18.0) (3.3.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->funasr) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->funasr) (1.0.8)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr)\n",
            "  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from oss2->funasr) (1.16.0)\n",
            "Collecting einops>=0.7 (from rotary-embedding-torch->funasr)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from rotary-embedding-torch->funasr) (2.3.0+cu121)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->funasr) (3.20.3)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr) (42.0.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->funasr) (2.22)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->funasr) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->funasr) (4.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->funasr) (3.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch->funasr) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->rotary-embedding-torch->funasr) (12.5.82)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->rotary-embedding-torch->funasr) (1.3.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, ffmpy, jaconv, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=bcee583012319df1cf04d95c2380fbff3d0d9e0f5030c8c07c44dc759f7dbad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=891ca18e7dd9f3a0fadbe0d2e682224f6ce10f3e4f176833c98843e50dc38fb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.3.4-py3-none-any.whl size=16416 sha256=b7f1b5271e6c69867fec3c9d97b6f729fe1de3f3ed144cdbf4806a396212298f\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/8f/2e/a730bf1fca05b33e532d5d91dabdf406c9b718ec85b01b1b54\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.18.6-py3-none-any.whl size=118355 sha256=9b7a5722569b646dee3b749512356f2462538e11c2a8e9f0ea2ec9d2a7436799\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/1c/df/6256a3d22097f6e1a30edd892de172054fd27875e0a349b4a4\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=ae063c3ff6bcfc62e1cea40fa7dafbb693493fc9c32c43e5df35bfe134d81616\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=cf5d603fae9ce1708b6d796d71cb79f1ab8db44b85ef0209952fb542210f913a\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built antlr4-python3-runtime ffmpy jaconv oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: pydub, jamo, jaconv, ffmpy, crcmod, antlr4-python3-runtime, addict, xxhash, websockets, uvloop, ujson, torch-complex, tomlkit, tensorboardX, simplejson, semantic-version, ruff, pytorch-wpe, python-multipart, python-dotenv, pycryptodome, orjson, omegaconf, kaldiio, jmespath, httptools, h11, einops, dnspython, dill, aiofiles, watchfiles, uvicorn, starlette, multiprocess, modelscope, hydra-core, httpcore, email_validator, pynndescent, httpx, aliyun-python-sdk-core, umap-learn, rotary-embedding-torch, gradio-client, fastapi-cli, datasets, aliyun-python-sdk-kms, oss2, fastapi, gradio, funasr\n",
            "Successfully installed addict-2.4.0 aiofiles-23.2.1 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 antlr4-python3-runtime-4.9.3 crcmod-1.7 datasets-2.18.0 dill-0.3.8 dnspython-2.6.1 einops-0.8.0 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 funasr-1.1.0 gradio-4.37.2 gradio-client-1.0.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 hydra-core-1.3.2 jaconv-0.3.4 jamo-0.4.1 jmespath-0.10.0 kaldiio-2.18.0 modelscope-1.16.0 multiprocess-0.70.16 omegaconf-2.3.0 orjson-3.10.6 oss2-2.18.6 pycryptodome-3.20.0 pydub-0.25.1 pynndescent-0.5.13 python-dotenv-1.0.1 python-multipart-0.0.9 pytorch-wpe-0.0.1 rotary-embedding-torch-0.6.4 ruff-0.5.1 semantic-version-2.10.0 simplejson-3.19.2 starlette-0.37.2 tensorboardX-2.6.2.2 tomlkit-0.12.0 torch-complex-0.4.4 ujson-5.10.0 umap-learn-0.5.6 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "f9f4f2c4fb294a5d9362064c2eb34dd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.83)] [Co\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [2 InRelease 15.6 kB/128 kB 12%] [Connecting to security.ubuntu.com (91.189.\u001b[0m\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [2 InRelease 67.7 kB/128 kB 53%] [Connecting to security.ubuntu.com (91.189.\u001b[0m\u001b[33m\r0% [2 InRelease 75.0 kB/128 kB 59%] [Connecting to security.ubuntu.com (91.189.\u001b[0m\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                    \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\u001b[33m\r                                                                    \r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\u001b[33m\r                                              \r0% [Waiting for headers]\u001b[0m\r                        \rHit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [858 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,410 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,674 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,263 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,996 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,596 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,127 kB]\n",
            "Fetched 13.2 MB in 2s (6,320 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "52 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXYAuMnigVlw",
        "outputId": "15a9abf1-7e9b-4b63-d119-9839a568ff82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting config\n",
            "  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modelscope"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd_ZHusxioHx",
        "outputId": "a1c615fe-34a2-4b75-b187-435a357137af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: modelscope in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.10/dist-packages (from modelscope) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from modelscope) (4.66.4)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from modelscope) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->modelscope) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->modelscope) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->modelscope) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import librosa\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import logging\n",
        "from modelscope.pipelines import pipeline as modelscope_pipeline\n",
        "from modelscope.utils.constant import Tasks\n",
        "from sqlalchemy import create_engine, Column, String, Integer, Text, ForeignKey\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker, relationship\n",
        "from sqlalchemy.exc import IntegrityError\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "import json\n",
        "import gradio as gr\n",
        "import config\n",
        "from dotenv import load_dotenv\n",
        "import gradio as gr\n",
        "from sqlalchemy import create_engine, Column, Integer, String, Text, ForeignKey\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import relationship, sessionmaker\n",
        "import logging\n",
        "import os\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from transformers import pipeline\n",
        "import requests"
      ],
      "metadata": {
        "id": "_dlgFjKYy_0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## configurações"
      ],
      "metadata": {
        "id": "n8CEAMC5qARh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "DATABASE_URL = \"sqlite:///database.db\"\n",
        "EMAIL_FROM = os.getenv(\"EMAIL_FROM\")\n",
        "EMAIL_PASSWORD = os.getenv(\"EMAIL_PASSWORD\")\n",
        "Base = declarative_base()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOm3EMBcguzY",
        "outputId": "bdf5b666-dc22-4955-9516-c0b3cabfc361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d928416d652f>:14: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## banco de dados"
      ],
      "metadata": {
        "id": "HCcFHfliqHBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Psicologo(Base):\n",
        "    __tablename__ = 'psicologos'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    nome = Column(String, unique=True)\n",
        "    email = Column(String, unique=True)\n",
        "\n",
        "class Paciente(Base):\n",
        "    __tablename__ = 'pacientes'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    nome = Column(String)\n",
        "    psicologo_id = Column(Integer, ForeignKey('psicologos.id'))\n",
        "    psicologo = relationship(\"Psicologo\", back_populates=\"pacientes\")\n",
        "\n",
        "Psicologo.pacientes = relationship(\"Paciente\", order_by=Paciente.id, back_populates=\"psicologo\")\n",
        "\n",
        "class Conversa(Base):\n",
        "    __tablename__ = 'conversas'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    paciente_id = Column(Integer, ForeignKey('pacientes.id'))\n",
        "    texto = Column(Text)\n",
        "    paciente = relationship(\"Paciente\", back_populates=\"conversas\")\n",
        "\n",
        "Paciente.conversas = relationship(\"Conversa\", order_by=Conversa.id, back_populates=\"paciente\")\n",
        "\n",
        "engine = create_engine(DATABASE_URL)\n",
        "Base.metadata.create_all(engine)\n",
        "Session = sessionmaker(bind=engine)"
      ],
      "metadata": {
        "id": "ErE7I8_Rh0Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No sistema de banco de dados, são armazenadas informações detalhadas sobre psicólogos, pacientes e suas conversas. Psicólogos têm seus nomes e e-mails registrados, garantindo unicidade para facilitar a identificação. Pacientes são associados a seus respectivos psicólogos, o que permite uma fácil consulta e acompanhamento. As conversas entre pacientes e o sistema são armazenadas cronologicamente, permitindo um rastreamento eficiente das interações ao longo do tempo. Esse esquema facilita a gestão e recuperação de dados essenciais para o funcionamento do sistema de suporte emocional."
      ],
      "metadata": {
        "id": "CJqbXwlsCDCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modelo"
      ],
      "metadata": {
        "id": "RJLwC8K0qLwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chamadas API do ChatGPT\n",
        "def ask_chatgpt(prompt, system_prompt=\"Você é um assistente psicológico virtual especializado em emergências psicológicas.\"):\n",
        "    url = \"https://api.openai.com/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": \"Bearer sk-proj-apikey\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"gpt-3.5-turbo\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "    response_data = response.json()\n",
        "\n",
        "    if 'choices' in response_data:\n",
        "        return response_data['choices'][0]['message']['content']\n",
        "    else:\n",
        "        print(\"Erro na resposta da API OpenAI:\", response_data)\n",
        "        return \"Erro ao processar a solicitação com o modelo GPT-3.5.\""
      ],
      "metadata": {
        "id": "pPDjJreKr7ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sistema utiliza uma função especializada para interagir com a API do ChatGPT, que fornece respostas baseadas em prompts específicos. O modelo é configurado para agir como um assistente psicológico, respondendo de maneira empática e contextualizada. Esta função é usada para gerar respostas que ajudam no suporte emocional contínuo, garantindo que os pacientes recebam orientações rápidas e pertinentes."
      ],
      "metadata": {
        "id": "H-fDIrpHCGvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## processamento de áudio"
      ],
      "metadata": {
        "id": "A9p1Td7QqO5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcessadorAudio:\n",
        "    def __init__(self, taxa_amostragem_alvo=16000, n_fft=1024, hop_length=512, n_mels=64, max_pad_len=400):\n",
        "        self.taxa_amostragem_alvo = taxa_amostragem_alvo\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mels = n_mels\n",
        "        self.max_pad_len = max_pad_len\n",
        "\n",
        "    def carregar_audio(self, caminho):\n",
        "        waveform, sample_rate = torchaudio.load(caminho)\n",
        "        if sample_rate != self.taxa_amostragem_alvo:\n",
        "            resample_transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=self.taxa_amostragem_alvo)\n",
        "            waveform = resample_transform(waveform)\n",
        "        return waveform\n",
        "\n",
        "    def extrair_caracteristicas(self, waveform):\n",
        "        mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=self.taxa_amostragem_alvo,\n",
        "            n_fft=self.n_fft,\n",
        "            hop_length=self.hop_length,\n",
        "            n_mels=self.n_mels\n",
        "        )\n",
        "        mel_spectrogram = mel_spectrogram_transform(waveform)\n",
        "        mel_spectrogram = mel_spectrogram.mean(dim=0)\n",
        "        pad = self.max_pad_len - mel_spectrogram.shape[-1]\n",
        "        if pad > 0:\n",
        "            mel_spectrogram = torch.nn.functional.pad(mel_spectrogram, (0, pad))\n",
        "        else:\n",
        "            mel_spectrogram = mel_spectrogram[:, :self.max_pad_len]\n",
        "        return mel_spectrogram.numpy().flatten()\n",
        "\n",
        "class DetectorEmocao:\n",
        "    def __init__(self):\n",
        "        self.modelo = modelscope_pipeline(task=Tasks.emotion_recognition, model=\"iic/emotion2vec_plus_large\")\n",
        "        self.labels_mapping = {\n",
        "            '生气/angry': 'angry',\n",
        "            '开心/happy': 'happy',\n",
        "            '中立/neutral': 'neutral',\n",
        "            '难过/sad': 'sad',\n",
        "            '<unk>': 'unknown',\n",
        "        }\n",
        "\n",
        "    def prever(self, caminho_audio):\n",
        "        rec_result = self.modelo(caminho_audio, granularity=\"utterance\", extract_embedding=False)\n",
        "        for result in rec_result:\n",
        "            predicted_emotion = self.labels_mapping[result['labels'][np.argmax(result['scores'])]]\n",
        "            return predicted_emotion"
      ],
      "metadata": {
        "id": "1QlR11TCi-nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O processamento de áudio começa com o carregamento e a preparação dos arquivos de áudio. Os áudios são ajustados para uma taxa de amostragem padrão e convertidos em espectrogramas Mel, que destacam as frequências presentes de maneira perceptualmente relevante. Este processamento inicial inclui a resampling (ajuste da taxa de amostragem), a transformação de Fourier (STFT) e a criação de espectrogramas Mel, que são essenciais para a análise precisa das emoções contidas no áudio. O espectrograma Mel é padronizado para um comprimento fixo para garantir consistência nos dados de entrada. Essas features extraídas são então utilizadas por um modelo especializado para identificar emoções como alegria, tristeza, raiva e neutralidade, permitindo uma compreensão detalhada do estado emocional dos pacientes a partir de suas mensagens de áudio."
      ],
      "metadata": {
        "id": "kPpaBmK8CXJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## processamento NLP"
      ],
      "metadata": {
        "id": "jbOzUjlVqSHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcessadorNLP:\n",
        "    def __init__(self):\n",
        "        self.analisador_sentimento = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "    def analisar_sentimento(self, texto):\n",
        "        resultado = self.analisador_sentimento(texto)\n",
        "        sentimento = resultado[0]['label']\n",
        "        mapeamento_sentimentos = {\n",
        "            \"1 star\": \"sad\",\n",
        "            \"2 stars\": \"neutral\",\n",
        "            \"3 stars\": \"neutral\",\n",
        "            \"4 stars\": \"happy\",\n",
        "            \"5 stars\": \"happy\"\n",
        "        }\n",
        "        return mapeamento_sentimentos.get(sentimento, \"neutral\")"
      ],
      "metadata": {
        "id": "4cx_7F_FjBlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para compreender o conteúdo textual das mensagens, o sistema utiliza o modelo BERT base-multilingual-uncased, que é um dos modelos de linguagem mais robustos e versáteis disponíveis. Este modelo foi treinado em uma ampla gama de textos em diversos idiomas, permitindo uma compreensão profunda e precisa do conteúdo emocional das mensagens. Textos transcritos dos áudios são analisados para identificar sentimentos predominantes, como felicidade, neutralidade ou tristeza. O modelo classifica o sentimento do texto em categorias como \"sad\", \"neutral\" e \"happy\". Essa análise ajuda a determinar o estado emocional do paciente com base no texto, garantindo que as respostas fornecidas sejam apropriadas e empáticas."
      ],
      "metadata": {
        "id": "ay2wGP_wCizl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## serviço email"
      ],
      "metadata": {
        "id": "3CR50uDiqVo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enviar_email(psicologo_email, assunto, conteudo):\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = EMAIL_FROM\n",
        "    msg['To'] = psicologo_email\n",
        "    msg['Subject'] = assunto\n",
        "\n",
        "    msg.attach(MIMEText(conteudo, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com:587')\n",
        "        server.starttls()\n",
        "        server.login(EMAIL_FROM, EMAIL_PASSWORD)\n",
        "        server.send_message(msg)\n",
        "        server.quit()\n",
        "        print(\"Email enviado com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao enviar o email: {e}. O processo continuará.\")\n"
      ],
      "metadata": {
        "id": "4QTt9uNUjHy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A comunicação com psicólogos é facilitada por um serviço de email automatizado. Relatórios detalhados das interações dos pacientes são gerados e enviados diretamente aos psicólogos, permitindo um acompanhamento contínuo. Este processo garante que os psicólogos estejam sempre informados sobre o progresso emocional de seus pacientes, auxiliando na gestão do tratamento de maneira eficiente."
      ],
      "metadata": {
        "id": "xTeX3aZQCn9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## assistente"
      ],
      "metadata": {
        "id": "fZ4W5jSjqYIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AssistenteAudioEmocional:\n",
        "    def __init__(self):\n",
        "        self.processador_audio = ProcessadorAudio()\n",
        "        self.detector_emocao = DetectorEmocao()\n",
        "        self.processador_nlp = ProcessadorNLP()\n",
        "        self.session = Session()\n",
        "        self.historico = []\n",
        "\n",
        "    def processar_audio(self, caminho_audio):\n",
        "        logging.info(\"Processando áudio...\")\n",
        "        return self.detector_emocao.prever(caminho_audio)\n",
        "\n",
        "    def transcrever_audio(self, caminho_audio):\n",
        "        logging.info(\"Transcrevendo áudio...\")\n",
        "        transcricao_path = caminho_audio.replace('.wav', '.txt')\n",
        "        os.system(f'whisper {caminho_audio} --model medium --task transcribe --language pt --output_dir /tmp/gradio/')\n",
        "        transcricao_path = os.path.join(\"/tmp/gradio\", os.path.basename(caminho_audio).replace('.wav', '.txt'))\n",
        "        with open(transcricao_path, 'r') as file:\n",
        "            transcricao = file.read()\n",
        "        return transcricao\n",
        "\n",
        "    def processar_texto(self, texto):\n",
        "        logging.info(\"Processando texto...\")\n",
        "        return self.processador_nlp.analisar_sentimento(texto)\n",
        "\n",
        "    def gerar_resposta(self, emocao_audio, emocao_texto, transcricao):\n",
        "        logging.info(\"Gerando resposta...\")\n",
        "        self.historico.append(f\"Paciente: {transcricao}\")\n",
        "        self.historico = self.historico[-4:]  # Manter apenas as últimas duas interações\n",
        "        prompt = (f\"Histórico: {' '.join(self.historico)}\\n\"\n",
        "                  f\"Transcrição do áudio: {transcricao} \\n\"\n",
        "                  f\"Emoção detectada no áudio: {emocao_audio} \\n\"\n",
        "                  f\"Emoção detectada no texto transcrito: {emocao_texto} \\n\"\n",
        "                  f\"Baseado na ciência psicológica, gere uma resposta para este paciente! Seja empático e tome cuidado com as palavras. Forneça respostas curtas, objetivas e completas. Não dê respostas pela metade. Lembre-se que o paciente está vulnerável e precisa de respostas rápidas e precisas. Responda de forma humanizada, não demonstre que é um chatbot. Lembre que você é um auxiliar do psicólogo, mas não substitui um. A resposta deve ter um parágrafo somente. NÃO CORTE AS RESPOSTAS. CONCLUA SEMPRE O RACIOCÍNIO. RESPONDA COMO UM HUMANO.\")\n",
        "        resposta = ask_chatgpt(prompt)\n",
        "        self.historico.append(f\"Assistente: {resposta}\")\n",
        "        return resposta\n",
        "\n",
        "    def salvar_conversa(self, paciente_id, texto):\n",
        "        conversa = Conversa(paciente_id=paciente_id, texto=texto)\n",
        "        self.session.add(conversa)\n",
        "        self.session.commit()\n",
        "\n",
        "    def enviar_relatorio(self, paciente_id):\n",
        "        paciente = self.session.query(Paciente).filter_by(id=paciente_id).first()\n",
        "        psicologo = paciente.psicologo\n",
        "        conversas = self.session.query(Conversa).filter_by(paciente_id=paciente_id).all()\n",
        "        historico = \"\\n\".join([c.texto for c in conversas])\n",
        "\n",
        "        assunto = f\"Relatório da Análise de Sentimentos do Paciente {paciente.nome}\"\n",
        "        conteudo = f\"Histórico da conversa:\\n{historico}\\n\\nResumo da conversa:\\n{self.resumir_conversa(historico)}\"\n",
        "        enviar_email(psicologo.email, assunto, conteudo)\n",
        "\n",
        "    def resumir_conversa(self, historico):\n",
        "        prompt = f\"Resuma o seguinte histórico de conversa, destacando as emoções mais presentes e os assuntos mais pertinentes em bullet points, não invente, apenas perceba e traga as emoções mais citadas, como se fosse o relatório resumido:\\n\\n{historico}\\n\\nResumo:\"\n",
        "        resumo = ask_chatgpt(prompt)\n",
        "        return resumo\n",
        "\n",
        "    def lidar_interacao(self, caminho_audio=None, texto=None, paciente_id=None):\n",
        "        if caminho_audio:\n",
        "            emocao_audio = self.processar_audio(caminho_audio)\n",
        "            transcricao = self.transcrever_audio(caminho_audio)\n",
        "            emocao_texto = self.processar_texto(transcricao)\n",
        "            resposta = self.gerar_resposta(emocao_audio, emocao_texto, transcricao)\n",
        "        elif texto:\n",
        "            emocao_texto = self.processar_texto(texto)\n",
        "            resposta = self.gerar_resposta('unknown', emocao_texto, texto)\n",
        "        else:\n",
        "            resposta = \"Nenhum áudio ou texto fornecido.\"\n",
        "\n",
        "        if paciente_id:\n",
        "            self.salvar_conversa(paciente_id, f\"Paciente: {texto or transcricao}\\nAssistente: {resposta}\")\n",
        "\n",
        "        return resposta\n",
        "\n",
        "    def gerar_relatorio(self):\n",
        "        conversas = self.session.query(Conversa).all()\n",
        "        if not conversas:\n",
        "            historico = \"\\n\".join(self.historico)\n",
        "        else:\n",
        "            historico = \"\\n\".join([c.texto for c in conversas])\n",
        "\n",
        "        resumo = self.resumir_conversa(historico)\n",
        "\n",
        "        relatorio = f\"Relatório da Análise de Sentimentos\\n\\n\"\n",
        "        relatorio += f\"Resumo da conversa:\\n{resumo}\\n\\n\"\n",
        "        relatorio += f\"Histórico completo da conversa:\\n{historico}\"\n",
        "\n",
        "        return relatorio"
      ],
      "metadata": {
        "id": "Lw_A3SksjOUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O assistente emocional integra todos os componentes do sistema, processando áudios e textos, analisando emoções e gerando respostas. Ele mantém um registro histórico das interações para fornecer respostas contextualmente apropriadas. Além disso, o assistente pode gerar relatórios das conversas e enviá-los por email aos psicólogos, facilitando o acompanhamento contínuo do estado emocional dos pacientes. Essa integração de funcionalidades permite um suporte emocional abrangente."
      ],
      "metadata": {
        "id": "SMaw2xbSCreg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Além de suas funções técnicas, o assistente foi cuidadosamente projetado com um foco específico nos prompts utilizados para gerar respostas. O prompt passado ao modelo GPT-3.5 é estruturado para garantir que as respostas sejam empáticas, humanizadas e completas. O objetivo é que o assistente responda de forma que os pacientes se sintam compreendidos e apoiados. Instruções claras são fornecidas ao modelo para evitar respostas fragmentadas e garantir que o raciocínio seja sempre concluído, promovendo uma interação que mimetiza o cuidado e a atenção de um profissional humano, sem substituir a função do psicólogo."
      ],
      "metadata": {
        "id": "5kYdv8nvDO7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "f--6eu43qb4A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RH6lvqcVec0l",
        "outputId": "11c5b8be-5e29-4b46-bd66-a9a8797209d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-07-11 07:37:03,032 - modelscope - WARNING - Model revision not specified, use revision: v2.0.5\n",
            "2024-07-11 07:37:03,604 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/iic/emotion2vec_plus_large\n",
            "2024-07-11 07:37:03,606 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/iic/emotion2vec_plus_large.\n",
            "2024-07-11 07:37:03,608 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/iic/emotion2vec_plus_large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the latest version of funasr-1.1.0\n",
            "Detect model requirements, begin to install it: /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/requirements.txt\n",
            "install model requirements successfully\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n",
            "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, /root/.cache/modelscope/hub/iic/emotion2vec_plus_large/model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-07-11 07:37:12,549 - modelscope - WARNING - No preprocessor field found in cfg.\n",
            "2024-07-11 07:37:12,553 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
            "2024-07-11 07:37:12,556 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/iic/emotion2vec_plus_large'}. trying to build by task and model information.\n",
            "2024-07-11 07:37:12,560 - modelscope - WARNING - No preprocessor key ('funasr', 'emotion-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://1e425223eba7ca6747.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1e425223eba7ca6747.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1e425223eba7ca6747.gradio.live\n"
          ]
        }
      ],
      "source": [
        "assistente = AssistenteAudioEmocional()\n",
        "\n",
        "def chat_interface(audio=None, text=None, paciente_id=None):\n",
        "    if audio is not None:\n",
        "        resposta = assistente.lidar_interacao(caminho_audio=audio, paciente_id=paciente_id)\n",
        "    elif text is not None:\n",
        "        resposta = assistente.lidar_interacao(texto=text, paciente_id=paciente_id)\n",
        "    else:\n",
        "        resposta = \"Por favor, forneça áudio ou texto para continuar.\"\n",
        "    return resposta\n",
        "\n",
        "def launch_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Assistente Psicológico Virtual\")\n",
        "        with gr.Row():\n",
        "            audio_input = gr.Audio(type=\"filepath\")\n",
        "            text_input = gr.Textbox(lines=2, placeholder=\"Digite sua mensagem aqui...\")\n",
        "        paciente_id = gr.Number(label=\"ID do Paciente\", precision=0)\n",
        "        output = gr.Textbox(label=\"Resposta do Assistente\")\n",
        "        submit_btn = gr.Button(\"Enviar\")\n",
        "        report_btn = gr.Button(\"Gerar Relatório\")\n",
        "\n",
        "        submit_btn.click(chat_interface, inputs=[audio_input, text_input, paciente_id], outputs=output)\n",
        "        report_btn.click(generate_report, inputs=[], outputs=gr.Textbox(label=\"Relatório\"))\n",
        "\n",
        "    demo.launch(share=True, debug=True)\n",
        "\n",
        "def generate_report():\n",
        "    report = assistente.gerar_relatorio()\n",
        "    return report\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    launch_interface()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A aplicação principal configura e lança uma interface de usuário amigável, permitindo que pacientes interajam facilmente com o assistente emocional. Os usuários podem enviar áudios ou textos e receber respostas imediatas. A interface também permite a geração de relatórios detalhados das conversas, que são úteis para os psicólogos no acompanhamento do tratamento. Essa interface acessível garante que os pacientes recebam suporte emocional contínuo e imediato, contribuindo significativamente para seu bem-estar."
      ],
      "metadata": {
        "id": "h9O5McgoDozC"
      }
    }
  ]
}
